{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f58860",
   "metadata": {},
   "source": [
    "# LIDC-IDRI Lung Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import datasets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from models.unet import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951f7f0",
   "metadata": {},
   "source": [
    "Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e83b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_dataset = datasets.load_dataset(\"jmanuelc87/lidc-idri-segmentation\")\n",
    "lung_dataset = lung_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)  # type: ignore\n",
    "lung_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a356e8",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f557b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    EPOCHS: int = 50\n",
    "    NUM_CLASSES: int = 1\n",
    "    BATCH_SIZE: int = 32\n",
    "    IMG_WIDTH: int = 192\n",
    "    IMG_HEIGHT: int = 192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687413e5",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Exploration of some samples of the dataset and its masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_rgb(mask):\n",
    "    num_arr = np.array(mask)\n",
    "    output = np.zeros(num_arr.shape[:2] + (3,))\n",
    "    output[num_arr == 255] = (255, 0, 0)\n",
    "    return output.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd80987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_overlay(image, segmented_image):\n",
    "    alpha = 1.0  # Transparency for the original image.\n",
    "    beta = 0.7  # Transparency for the segmentation map.\n",
    "    gamma = 0.0  # Scalar added to each sum.\n",
    "\n",
    "    segmented_image = cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    image = cv2.addWeighted(image, alpha, segmented_image, beta, gamma, image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(dataset: datasets.Dataset, qty=10):\n",
    "    fig, ax = plt.subplots(qty, 3, figsize=(12, 28))\n",
    "\n",
    "    for i, item in enumerate(dataset):\n",
    "        if i >= qty:\n",
    "            break\n",
    "\n",
    "        ax[i, 0].axis(\"off\")\n",
    "        ax[i, 0].imshow(item[\"patch\"], cmap=\"gray\")  # type: ignore\n",
    "\n",
    "        ax[i, 1].axis(\"off\")\n",
    "        ax[i, 1].imshow(item[\"patch_mask\"], cmap=\"gray\")  # type: ignore\n",
    "\n",
    "        patch = np.array(item[\"patch\"])  # type: ignore\n",
    "        patch = np.transpose(np.stack([patch, patch, patch]), axes=(1, 2, 0))\n",
    "\n",
    "        mask = num_to_rgb(item[\"patch_mask\"])  # type: ignore\n",
    "        image = image_overlay(patch, mask)\n",
    "\n",
    "        ax[i, 2].axis(\"off\")\n",
    "        ax[i, 2].imshow(image, cmap=\"gray\")\n",
    "\n",
    "\n",
    "plot(lung_dataset[\"train\"], qty=7)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068110b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Preparation of the dataset using albumentations library for augmenting the dataset samples using the transformations:\n",
    "\n",
    "- RandomCrop\n",
    "- CenterCrop\n",
    "- SquareSymmetry\n",
    "- GaussNoise\n",
    "- Normalize\n",
    "- ToTensor\n",
    "\n",
    "And creation of the train, valid and test splits for datasets and dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(\n",
    "            height=TrainingConfig.IMG_HEIGHT,\n",
    "            width=TrainingConfig.IMG_WIDTH,\n",
    "            interpolation=cv2.INTER_NEAREST,\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.Normalize(\n",
    "            mean=(0.0, 0.0, 0.0),\n",
    "            std=(1.0, 1.0, 1.0),\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "valid_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(\n",
    "            height=TrainingConfig.IMG_HEIGHT,\n",
    "            width=TrainingConfig.IMG_WIDTH,\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.Normalize(\n",
    "            mean=(0.0, 0.0, 0.0),\n",
    "            std=(1.0, 1.0, 1.0),\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image_transforms(transformations):\n",
    "\n",
    "    def wrapper(row):\n",
    "        augmented = []\n",
    "        keys = row.keys()\n",
    "        for item in zip(*row.values()):\n",
    "            items = {k: np.array(v) for k, v in zip(keys, item)}\n",
    "            values = transformations(**items)\n",
    "            augmented.append(values)\n",
    "\n",
    "        for key in keys:\n",
    "            row[key] = [np.expand_dims(item[key], axis=-1) for item in augmented]\n",
    "\n",
    "        return row\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b45980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns not needed and rename the ones needed to be interpreted by albumentations library\n",
    "new_lung_dataset = (\n",
    "    lung_dataset.remove_columns([\"image\", \"image_mask\", \"malignancy\", \"cancer\"])\n",
    "    .rename_column(\"patch\", \"image\")\n",
    "    .rename_column(\"patch_mask\", \"mask\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(lung_dataset):\n",
    "    lung_train_dataset = (\n",
    "        lung_dataset[\"train\"]\n",
    "        .with_format(\"tensorflow\")\n",
    "        .with_transform(map_image_transforms(train_transforms))\n",
    "        .to_tf_dataset(\n",
    "            columns=\"image\",\n",
    "            label_cols=\"mask\",\n",
    "            batch_size=TrainingConfig.BATCH_SIZE,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    tmp_dataset = lung_dataset[\"test\"].train_test_split(train_size=0.5)\n",
    "\n",
    "    lung_valid_dataset = (\n",
    "        tmp_dataset[\"train\"]\n",
    "        .with_format(\"tensorflow\")\n",
    "        .with_transform(map_image_transforms(valid_transforms))\n",
    "        .to_tf_dataset(\n",
    "            columns=\"image\",\n",
    "            label_cols=\"mask\",\n",
    "            batch_size=TrainingConfig.BATCH_SIZE,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    lung_test_dataset = (\n",
    "        tmp_dataset[\"test\"]\n",
    "        .with_format(\"tensorflow\")\n",
    "        .with_transform(map_image_transforms(valid_transforms))\n",
    "        .to_tf_dataset(\n",
    "            columns=\"image\",\n",
    "            label_cols=\"mask\",\n",
    "            batch_size=TrainingConfig.BATCH_SIZE,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return lung_train_dataset, lung_valid_dataset, lung_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13679eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_dataset,\n",
    "    valid_dataset,\n",
    "    test_dataset,\n",
    ") = create_datasets(new_lung_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813724e",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Creation of a UNet model in pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(num_classes=TrainingConfig.NUM_CLASSES)\n",
    "\n",
    "cosine_decay = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3, decay_steps=100\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=cosine_decay),  # type: ignore\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=TrainingConfig.EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataset):\n",
    "\n",
    "    num_batches_to_process = 1\n",
    "    tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "\n",
    "    for idx, data in enumerate(dataset):\n",
    "\n",
    "        if idx == num_batches_to_process:\n",
    "            break\n",
    "\n",
    "        batch_img, batch_mask = data[0], data[1]\n",
    "        pred_all = (model.predict(batch_img)).astype(\"float32\")\n",
    "        pred_all = pred_all.argmax(-1)\n",
    "        batch_img = (batch_img * 255).astype(\"uint8\")\n",
    "\n",
    "        for i in range(0, len(batch_img)):\n",
    "\n",
    "            fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "            # Display the original image.\n",
    "            ax1 = fig.add_subplot(1, 4, 1)\n",
    "            ax1.imshow(batch_img[i], cmap=\"gray\")\n",
    "            ax1.title.set_text(\"Actual frame\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Display the ground truth mask.\n",
    "            true_mask = batch_mask[i]\n",
    "            ax2 = fig.add_subplot(1, 4, 2)\n",
    "            ax2.set_title(\"Ground truth labels\")\n",
    "            ax2.imshow(true_mask, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Display the predicted segmentation mask.\n",
    "            pred_mask = pred_all[i][:, :, np.newaxis]\n",
    "\n",
    "            print(pred_mask.shape)\n",
    "\n",
    "            ax3 = fig.add_subplot(1, 4, 3)\n",
    "            ax3.set_title(\"Predicted labels\")\n",
    "            ax3.imshow(pred_mask, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(model, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung-segmentation-lidc-idri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
